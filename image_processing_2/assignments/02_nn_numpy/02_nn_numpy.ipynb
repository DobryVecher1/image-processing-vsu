{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh-9yK1FDOfo"
      },
      "source": [
        "# Полносвязная (искусственная) нейронная сеть\n",
        "\n",
        "В этом задании вам предстоит реализовать полносвязную двухслойную нейронную сеть с помощью библиотеки Numpy и применить её для классификации.\n",
        "\n",
        "Архитектура сети будет выглядеть следующим образом:\n",
        "\n",
        "Входные данные $→$ Линейный слой $→$ Функция активации $→$ Линейный слой $→$ Softmax $→$ Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdFN6FnnGYv6"
      },
      "source": [
        "# 1. Датасет\n",
        "\n",
        "Для задачи будем использовать датасет CIFAR-10 [[ссылка](https://www.cs.toronto.edu/~kriz/cifar.html)]. Загрузим датасет, приведем значения пикселей к интервалу $[0, 1]$, а также осуществим one-hot кодирование целевого вектора.\n",
        "\n",
        "Отобразите несколько изображений и соответствующие им классы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "\n",
        "# Загрузка датасета\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "valset = datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "num_classes = 10\n",
        "\n",
        "x_train = np.stack([np.array(img)/255. for img, _ in trainset])  # (N, H, W, C)\n",
        "x_train = x_train.reshape(-1, 32*32*3) # (N, H*W*C)\n",
        "y_train = np.array([label for _, label in trainset], dtype=int)\n",
        "# one hot representation\n",
        "y_train = np.eye(num_classes)[y_train]\n",
        "\n",
        "x_val = np.stack([np.array(img)/255. for img, _ in valset])\n",
        "x_val = x_val.reshape(-1, 32*32*3)\n",
        "y_val = np.array([label for _, label in valset], dtype=int)\n",
        "# one hot representation\n",
        "y_val = np.eye(num_classes)[y_val]\n",
        "\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKzxBmB4JGHB"
      },
      "source": [
        "# 2. Реализация слоев нейронной сети\n",
        "В этом пункте необходимо реализовать forward pass и backward pass для используемых слоев (см. `nn_numpy_funcs.py`). Функции должны возвращать либо результат действия слоя на входные данные, либо, если `get_grad=True`, градиент(ы).\n",
        "\n",
        "1. **Линейный слой**\n",
        "$$ f(x, W, b) = xW + b $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOjcCXKGMTcH"
      },
      "source": [
        "2. **ReLU**\n",
        "\n",
        "В качестве функции активации будем использовать ReLU:\n",
        "$$ ReLU(x) = max(x, 0)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNfpId2GNAi5"
      },
      "source": [
        "3. **Softmax + Cross-entropy loss**\n",
        "\n",
        "$$s_i(x) = \\frac{e^{x_i}}{\\sum\\limits_{j}^K e^{x_j}} $$\n",
        "$$CE(y, \\hat{y}) = - \\frac{1}{N}\\sum\\limits_i^N \\sum\\limits_j^K y_j \\ln\\hat{y_j}$$\n",
        "где $K-$количество классов, $N-$ количество объектов.\n",
        "\n",
        "Если мы используем Softmax вместе с функцией потерь в виде кросс-энтропии, то удобно объединить их вместе в один слой из-за удобства получаемых выражений. Напишите выражения для функции потерь и для градиента (можно без полного вывода) и реализуйте функцию аналогично прошлым пунктам."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74AJyGhWPhbr"
      },
      "source": [
        "# 3. Обучение\n",
        "До начала обучения необходимо сделать еще несколько шагов:\n",
        "\n",
        "- **Инициализация весов**. Начальные значения матриц весов могут сильно влиять на ход обучения. Инициализируйте матрицы $W$ и $b$ случайными числами из нормального распределения (функция `init_weights()`).\n",
        "- Выбор **темпа обучения (learning rate)**. Гиперпараметр, отвечающий за размер шага в алгоритме градиентного спуска.\n",
        "- Выбор **количества нейронов в скрытом слое**\n",
        "- **Размер батча**. В глубоком обучении через нейронную сеть редко пропускают сразу весь датасет. Вместо этого входные данные делят на части, которые называются **батчи (batch)**, и пропускают по очереди через сеть, обновляя веса после каждой итерации. Когда все батчи из датасета были использованы для forward и backward проходов, заканчивается **эпоха обучения**. Такой подход позволяет избежать проблем с памятью (датасет может не помещаться в память целиком), а также улучшить сходимость (обновляем веса после каждого батча, а не только один раз после прохода всего датасета).\n",
        "\n",
        "    Выберите размер батча и разбейте датасет на части (функция `get_batches()`).\n",
        "- Метрика **accuracy** будет использоваться как оценка качества модели (функция `accuracy()`)\n",
        "\n",
        "Реализуйте процесс обучения сети с заданными параметрами. В конце каждой эпохи выводите значения тренировочного и валидационного **лосса**, а также метрики\n",
        "**Accuracy** (функция `accuracy()`). Для удобства и стабильности перед обновлением весов следует разделить значения градиентов на размер батча. В конце обучения постройте зависимости лоссов и метрик от номера эпохи.\n",
        "\n",
        "Вам необходимо достичь значения Accuracy на валидационном датасете в 50% или более."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T16OvlFQM-Ay"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCH =\n",
        "BATCH_SIZE_TRAIN =\n",
        "BATCH_SIZE_VAL =\n",
        "\n",
        "INPUT_SIZE = 32 * 32 * 3 # размер картинки\n",
        "HIDDEN_SIZE =\n",
        "OUTPUT_SIZE = 10 # 10 классов\n",
        "LR =\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# for epochs\n",
        "\n",
        "    # for train batches\n",
        "    \n",
        "\n",
        "    # for val batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDjcILHW9_RQ"
      },
      "source": [
        "## **Перед отправкой сохраните файлы в следующем формате: 02_Фамилия.ipynb и nn_numpy_funcs.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Q6N2Is-BpO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOiKhgsuaumjZP3YxV+a3Ui",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
